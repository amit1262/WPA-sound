\section{Introduction}
Knowing direction of speaker can be quite useful in small gatherings e.g. meetings and seminars. Since smartphones are getting more and more pervasive day by day, so smartphone based direction detection is quite useful.  Consider a scenario wherein a deaf person is attending the meeting with other people. He relies on lip/gesture reading of the speaker to understand what is being discussed. In order to be able to lip-read the speaker, it is important for him to know where to look for the speaker. So, real-time direction detection becomes quite critical here. If the person happens to have a smartphone, then it can be used to estimate the direction of the sound and the person can just look at the smartphone to find out where to look for the speaker.

Another possible application could be in camera automation e.g. a video camera in a conference room can be automatically rotated to capture the speaker as well as audience if they also participate in discussion. A smartphone can be used to find out direction of the sound and then rotate the camera accordingly. We need to connect actuators on the camera and connect a smartphone with them. Depending on the angle detected by the Smartphone, actuators can rotate the camera accordingly. Although the video camera might also have microphones but then we need to program each camera and given the fact that there is no standard operating system for camera, it becomes challenging to develop a generic solution. On the other hand, a single smartphone can be used for multiple cameras. 

Most of the previous work in acoustic localization have used microphone arrays with more than 2 microphones. For example, acoustic localization of everyday sounds by Guo et.al. \cite{everydaysounds} focused on localization of different sounds but they used 6 microphones for their study compared to our approach using only 2 microphones. TDOA based methods have been studied before and used for sound localization. For example Murray et.al in \cite{murray2004robotics} used interaural time difference and cross-correlation for their prototype of robotic acoustic system. Their work also uses TDOA on a linux based robot prototype. Results presented in \cite{murray2004robotics} show a delay of 1 second for their experiments with a distance of 1 meter from the robot. Our approach is applicable to any off-the-shelf android smartphone which supports stereo recording. Our application can estimate angles in less than 1 second. 

Although a microphone array of more than 2 microphones can give more accuracy if microphones are placed properly [cite a paper here?????] but this often requires a complex setup and it becomes difficult to carry it around all the time making it hard to use in scenarios described above. 
Smartphones on the other hand are always carried by people. Many smartphones today have more than one microphones available on-board which potentially can be used for sound direction detection. Since these microphones are located at different positions and are separated by some distance, so the audio signals received at both the microphones might differ in amplitude and time of arrival depending on the position of sound source with respect to Smartphone. This difference in time of arrival can be used to estimate the direction of incoming sound. We have developed an Android application which leverage two microphones available on a smartphone to provide a near real-time estimate of sound direction. Two microphones on the smartphone can capture two separate audio signals in stereo recording mode. We compute difference in time of arrival of these two signals using cross-correlation and then map this delay to the angle of arrival. All processing is done on smartphone itself and no cloud connectivity is required. Also, our method doesn't require any sort of signal processing and we don't need to store the incoming sound stream to phone memory, the analysis is done directly on the incoming data stream. This paper discusses the results of our experiment with white noise as the sound source.

