\section{Introduction}
Detecting direction of speaker can be quite useful in small gatherings e.g. meetings and seminars. Since smartphones are getting more and more pervasive day by day, so smartphone based sensing applications are quite useful.  Consider a scenario wherein a deaf person is attending the meeting. He relies on lip/gesture reading of the speaker to understand what is being discussed. In order to be able to lip-read the speaker, it is important for him to know where to look for the speaker. So, real-time direction detection becomes quite critical here. If the person happen to have a smartphone, then it can be used to estimate the direction of the sound and the person can just look at the smartphone to find out where to look for the speaker.

Another possible application could be in camera automation e.g. a video camera in a conference room can be automatically rotated to capture the speaker as well as audience if they also participate in discussion. For this, we need to install actuators on the camera and attach a smartphone with the camera. Depending on the angle detected by the Smartphone, actuators can rotate the camera accordingly.

Direction of the speaker can be detected using multiple microphones or microphone array as described in \cite{everydaysounds} [cite papers here]. But, this requires a dedicated setup of microphone hardware which is not possible to carry around all the time especially in above described scenarios.

Smartphones on the other hand are always carried by the people. Many of the smartphones have more than one microphones available on-board which potentially can be used for sound direction detection. Since these microphones are located at different positions and are separated by some distance, so the signals received at both the microphones can differ in amplitude and time of arrival depending on the position of source.This difference in amplitude and time of arrival can be used to estimate the direction of incoming sound. We have developed an Android application which leverage two microphones available on a smartphone to provide a real-time estimate of sound direction. Two microphones on the smartphone can capture two separate audio signals in stereo recording mode. We compute difference in time of arrival of these two signals at the two microphones to estimate angle of arrival of the sound source. Using signal convolution, we find lag between the two received sound sample arrays, then simply using cosine law, angle of arrival is estimated. All processing is done on smartphone itself and hence no cloud connectivity is required. Also, our method doesn't require any sort of signal processing and we don't need to store the incoming sound stream to phone memory, the analysis is done directly on the incoming data stream. Since the sound source can be either white noise or human voice etc., so in this paper, we discuss the results of our experiment with white noise as the sound source.

